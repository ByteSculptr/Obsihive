Sure! Here's a fully rewritten version of the README, tailored as if **ObsiHive** is a self-built, original project without any trace of Vercelâ€™s template origin:

---

# <a href="https://chat.obsihive.ai/"><img src="public/logo.png" alt="ObsiHive Logo" width="40" /></a> ObsiHive: AI Chatbot Platform

<p align="center">
  <strong>ObsiHive</strong> is a fully open-source, production-ready AI chatbot platform designed for seamless deployment, extensibility, and blazing-fast performance.
</p>

<p align="center">
  <a href="#features"><strong>Features</strong></a> Â·
  <a href="#supported-models"><strong>Supported Models</strong></a> Â·
  <a href="#getting-started"><strong>Getting Started</strong></a> Â·
  <a href="#deploy"><strong>Deploy</strong></a>
</p>

---

## ğŸš€ Features

- **Built with Next.js 14**
  - Uses the App Router and React Server Components for efficient routing and rendering
  - Full support for Server Actions for enhanced backend integration

- **AI Integration SDK**
  - Unified API for interacting with LLMs
  - Easily extend to new model providers
  - Built-in support for structured output, tool usage, and more

- **Modern UI Toolkit**
  - Built with Tailwind CSS and shadcn/ui for flexible, accessible design
  - Component primitives powered by Radix UI

- **Persistent Storage**
  - PostgreSQL (via Neon) to store user sessions and chat history
  - Blob storage for handling files and media uploads

- **Authentication**
  - Built-in secure user authentication using NextAuth.js
  - Social login and session management ready out-of-the-box

---

## ğŸ¤– Supported Models

ObsiHive is built to be model-agnostic. Out of the box, it supports the following AI providers:

- [OpenAI](https://openai.com)
- [Anthropic](https://www.anthropic.com)
- [xAI](https://x.ai)
- [Cohere](https://cohere.com)
- And many more with simple config changes

Custom models or APIs can be added with minimal changes using the SDK interface.

---

## ğŸ§  Use Cases

- AI customer support assistant
- Research or productivity chatbot
- Internal documentation Q&A bot
- Education and tutoring interface

---

## ğŸ›  Getting Started Locally

To run ObsiHive on your local machine, follow these steps:

### 1. Clone the Repository

```bash
git clone https://github.com/your-org/obsihive.git
cd obsihive
```

### 2. Install Dependencies

```bash
pnpm install
```

### 3. Setup Environment Variables

Create a `.env` file at the root of the project. Use `.env.example` as a guide to define your secrets and keys (AI providers, database URL, etc).

> âš ï¸ Do not commit your `.env` file. Keep your secrets secure.

### 4. Start the Development Server

```bash
pnpm dev
```

Open your browser and navigate to [http://localhost:3000](http://localhost:3000) to start chatting with your AI assistant.

---

## â˜ï¸ Deploy

You can deploy ObsiHive to any hosting provider that supports Node.js and PostgreSQL. We recommend platforms like:


- Render
- Fly.io
- AWS / GCP / Azure
- Docker (self-hosted)

Ensure your environment variables are correctly configured in your deployment dashboard or CI/CD pipeline.

---

## ğŸ’¡ Roadmap

- [ ] Multi-user workspace support
- [ ] Memory-based context threads
- [ ] Plugin system for external APIs
- [ ] Voice-to-text and speech synthesis
- [ ] Admin dashboard and analytics

---

## ğŸ¤ Contributing

We welcome contributions! Please open an issue or submit a PR for bug fixes, new features, or improvements.

---

## ğŸ“„ License

This project is open-source and MIT licensed.

---

## ğŸŒ Live Demo

Check out the live instance: [chat.obsihive.ai](https://chat.obsihive.ai)

---
